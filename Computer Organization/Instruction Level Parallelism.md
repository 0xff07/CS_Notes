# Instruction Level Parallelism

如果我們思考 Pipeline 實際上是在做什麼的話，我們會發現：可以做到 Pipeline 的理由，是因為「指令之間需要的硬體相依性可以拆開」，使得「A 指令在使用硬體 2 時，B 指令可以使用硬體 1，而兩者不會衝突」。找出這種特性之後就可以把他 Pipeline，進而讓硬體效能更好。利用這種「不會互相衝突」的性質，並進一步讓指令間的並行性更好，這就是 Instruction Level Parallelism 的意義。

# Pipelining

一般地來說，Pipelinine 是一種讓「指令之間的執行彼此重疊」的技巧。作法可以想像成「把 CPU 不同的部分，當成工廠生產線的不同步驟」，而要生產的東西就是「完整執行的指令」。再做這件事情的時候，可以觀察到兩件事：

1. 生產線中最慢的步驟，決定整條生產線每個階段時間。
2. 「單位時間內生產出多少東西」作為生產線效率的指標。

# 硬體架構

要討論 Pipeline 要先有一個硬體的基礎。這邊假設一個 5 個階段的 RISC 架構。

==只有暫存器中的資料才可以保存超過一個 clock 的時間==。

# 拉扯效能的因素

Pipeline 可以節省時間的因素是：

1. 指令每個執行階段彼此重疊，把需要的時間減少。

但另一方面來說，有一些因素會拉長每個指令的執行時間：

1. 增加的元件帶來的延遲：==同樣指令走完整條 Pipeline 的時間，會比走完一個 Single Cycle 的時間還要長==。這是因為Single Cycle 需要經過的硬體，Pipeline 全部都會走過。但除了這些，還會有更多新的硬體帶來的延遲： Pipeline Register 的 Setup time (要等所有暫存器輸出訊號達到穩定的時間)、Clock 訊號抵達每個部分的時間差 (這叫做 Clock Skew)、更多元件的 Propogation Delay、更多控制訊號加入。這些都會花上更多時間。
2. ==Clock Cycle 必須遷就整條生產線最慢的階段==：所以就算有些階段可以更快做完，在每個階段必須遷就於最慢階段的狀況下，這個等待的時間就是 Pipeline 浪費掉的時間。

所以，Pipeline 階段分得越細，雖然可以因為重疊的部分越多，而節省掉越多時間，但隨著上述延遲的因素，在階段增加時，會無可避免的使得 Pipeline 的加速達到一個上限。

假定時間單位是 1 ns (姑且稱他 1 個 Cycle 好了)，並且簡單假設指令分成 3 類：一類是 ALU 相關，走完整條 Data Path 需要 4 個 cycle; 另外一類指令是 Branch 指令，假設每個指令需要 4 個 cycle; 最後一類是記憶體相關的指令，每個指令需要 5 個 cycle。而且假設某個應用情境下，ALU 的指令佔了 40%、Branch 類指令佔了 20%，而記憶體相關的指令佔了 40%。在這個狀況下，平均一個指令時間的期望值是：
$$
\sum_{i}P_iT_i = 4 \cdot 40\% + 4 \cdot 20\% + 5 \cdot 40\% = 4.4(cycle) = 4.4(ns)
$$
因為現在一個 cycle 是 1 ns，所以需要的時間是 4.4 ns。

現在假設 Pipeline 之後，發現最長的階段只需要 1.2 ns。這時，雖然發現 Clock Cycle 需要變成 1.2 ns，但 Pipeline 最理想狀況下，每 1.2 ns ，生產線就有一條完整執行的指令出爐，所以每個指令需要的時間就是 1.2 ns。 雖然時脈變慢，但速度快了 $4.4/1.2 \approx 3.6$ 倍。

上面說這是「最理想的狀況」。實際上並沒有這麼美好。有可能：

1. 假設現在要「生產」連續兩道指令。後一到指令要前一道指令算出來的東西。但這個東西要到最後一個階段才會寫回記憶體，但後一道指令在第 2 階段就要拿到他。
2. 其種一種作法是全部的人停工，等到要做完的人把資料做完送回去後，大家再開工。這件事情叫做 stall。

# Hazard

1. *Structural Hazard*：每個硬體在某一個階段只能做一件事
2. *Data Hazard*：因為資料相依性而產生的問題
3. *Control Hazard*：因為不知道 branch 會往哪邊跳而產生的問題

## Structural Hazard

一個硬體一次只能做某件事。比如說 ALU 不能同時要算 effective address，又要同時做算數運算; 記憶體不能同時讀又同時寫入。